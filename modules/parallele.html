<module title="Parallélisme, concurrence"
with-contents="true"
module-name="para"
draft="false"
>
<contents>
<section id="introduction" title="Introduction">
<p>
OCaml permet différentes sortes de parallélisme/concurrence:
</p>
<ul>
<li>par l'utilisation de threads (ou processus légers),</li>
<li>via des processus lourds et de la communication inter-processus,</li>
<li>ou en utilisant des bibliothèques comme <doc href="#async">Async</doc>
   ou <doc href="#lwt">Lwt</doc> permettant de ne pas bloquer le programme
  sur des opérations potentiellement bloquantes
  (lectures/écritures de fichiers, entrées/sorties réseau, attente d'événements
   d'interfaces graphiques, ...).</li>
</ul>
<p>
Parallélisme et
concurrence sont deux choses différentes<note>On pourra lire à ce sujet
<ext-a href="http://existentialtype.wordpress.com/2014/04/09/parallelism-and-concurrency-revisited/">ce billet de Robert Harper</ext-a>.</note>.
</p>
<p>
La concurrence est l'accès simultané par plusieurs processus à une même ressource.
Il convient en général de protéger ces accès afin de s'assurer qu'un seul processus
à la fois accède à la ressource, de façon à ce qu'il ne soit pas interrompu
pendant l'opération qui concerne cette ressource. Un exercice classique
est la gestion d'un compteur pour obtenir des identifiants uniques.
</p>
<p>
Un algorithme de type <ext-a href="http://fr.wikipedia.org/wiki/MapReduce">MapReduce</ext-a>
utilise le parallélisme pour effectuer de nombreux calculs simultanément, mais
sans concurrence entre eux à priori, chacun utilisant ses propres ressources. Les
résultats de ces calculs sont ensuite agrégés.
</p>
<p>
Il est donc tout à fait possible d'avoir des calculs en parallèle sans concurrence,
de même que les problèmes de concurrence peuvent être traités avec un pseudo-parallélisme,
comme c'est le cas avec les bibliothèques <ext-a href="http://ocsigen.org/lwt/">Lwt</ext-a>
et  <ext-a href="http://janestreet.github.io/">Async</ext-a>.
</p>
<p>
Un<note>Un autre problème est
que pour l'instant certaines parties du runtime ne sont pas réentrantes.</note>
problème d'OCaml vis-à-vis du parallélisme et de la concurrence est que le
glaneur de cellules (<em>garbage collector</em>, ou GC) n'est pas concurrent
et que, lorsqu'il entre en action, il bloque tout le processus en cours,
y compris les éventuels threads (processus légers).
Des travaux de recherche sont en cours pour fournir un GC concurrent à OCaml.
</p>
<p>
Nous allons maintenant explorer les différentes
solutions<note>Il existe également
<ext-a href="http://jocaml.inria.fr/">Jocaml</ext-a> que nous
ne présenterons pas ici car il s'agit d'une extension d'OCaml.</note>
pour effectuer des calculs en parallèle et/ou en concurrence, selon les
trois approches listées plus haut. Chaque fois, nous listerons les
bibliothèques utilisables mais nous nous contenterons d'exemples sur seulement
certaines d'entre elles.
</p>
</section>

<section id="monads" title="Monades et (non-)concurrence">
<p id="lwt">
La bibliothèque <ext-a href="http://ocsigen.org/lwt/">Lwt</ext-a> (pour
<em>Lightweight threads</em>, ou processus légers légers) permet de simuler
l'utilisation de threads en profitant du fait que certaines opérations
sont bloquantes (les entrées/sorties ou l'attente d'autres événements)
et qu'en attendant il est possible d'exécuter d'autres parties du code.
</p>
<subsection id="lwt-principes" title="Principes">
<p>
La bibliothèque Lwt utilise une monade<note>Si on ne connaît pas les monades, on
pourra lire les trois billets d'introduction par Bartosz Milewski:
<ext-a href="http://bartoszmilewski.com/2011/01/09/monads-for-the-curious-programmer-part-1/">1</ext-a>,
<ext-a href="http://bartoszmilewski.com/2011/03/14/monads-for-the-curious-programmer-part-2/">2</ext-a>,
<ext-a href="http://bartoszmilewski.com/2011/03/17/monads-for-the-curious-programmer-part-3/">3</ext-a>.</note> basée sur un type représentant les "threads" Lwt, <ml>Lwt.t</ml>, et les deux opérations
<ml>Lwt.bind</ml> et <ml>Lwt.return</ml>.
</p>
<p>
Au lieu d'utiliser les fonctions d'entrée/sortie habituelles comme <ml>Pervasives.input_line</ml>,
on utilisera les variantes fournies par Lwt, comme <ml>Lwt_io.read_line</ml>. Regardons leurs
types respectifs:
</p>
<oc-eval>Pervasives.input_line;;
Lwt_io.read_line;;
</oc-eval>
<p>
Hormis le fait que <ml>Lwt_io</ml> définit un nouveau type pour les canaux de lecture,
ce qui différencie les deux fonctions est le type de retour. Dans le cas de
<ml>Lwt_io.read_line</ml>, c'est un thread Lwt qui est retourné. Ce thread Lwt sera
en attente de pouvoir lire sur le canal indiqué, et la fonction <ml>Lwt_io.read_channel</ml>
retournera immédiatement sans bloquer.
</p>
<p>
Pour utiliser la ligne lue par la fonction, on utilisera la fonction <ml>Lwt.bind</ml>,
qui prend en paramètre un thread Lwt et une fonction. Cette fonction sera appelée quand
le thread Lwt aura terminé, avec en paramètre la valeur retournée par le thread Lwt:
</p>
<oc-eval>Lwt.bind;;</oc-eval>
<p>La fonction en paramètre de <ml>Lwt.bind</ml> retourne elle aussi un thread Lwt,
ceci afin de pouvoir composer les appels de fonctions.
</p>
<p>
Pour créer un thread Lwt retournant une valeur, il suffit d'utiliser la deuxième opération
de la monade, <ml>Lwt.return</ml>, qui prend une valeur et en fait un thread Lwt qui
est déjà terminé:
</p>
<oc-eval>Lwt.return;;
Lwt.return "hello";;</oc-eval>
<p>
A ce point, on peut se rendre compte qu'il n'y a pas de réel parallélisme, puisque
les threads Lwt ne sont pas créés pour exécuter une fonction en parallèle, comme le
permettent les threads systèmes (avec <ml>Thread.create</ml> évoqué plus loin), mais
pour empaqueter une valeur dans un type (le type de la monade).
</p>
<p>Le "parallélisme" vient du fait que Lwt fournit des fonctions non bloquantes pour les
entrées/sorties, et son moteur s'occupe de créer les threads Lwt représentant les
attentes correspondant à ces entrées/sorties, et de signaler ces threads comme
terminés lorsque l'attente est terminée<note>En utilisant des sélecteurs sur les
descripteurs de fichiers concernés. Voir la documentation pour plus de détails.</note>.
Cela signifie que tout ce qui n'est pas en attente d'une entrée/sortie pourra
s'exécuter, ce qui fournit une forme de parallélisme entre ce qui attend et ce qui
n'a pas besoin d'attendre.
</p>
<p>Il n'y a cependant pas de parallélisme entre les parties du code qui n'ont pas besoin
d'attendre. Si une partie met potentiellement du temps à s'exécuter ou si,
pour une raison ou une autre, elle fait appel à une fonction bloquante,
il convient de la faire s'exécuter dans un thread léger séparé. Lwt offre pour
cela la fonction <ml>Lwt_preemptive.detach</ml>.
</p>
<p>Ce modèle évite bien des problèmes de concurrence que l'on rencontre
lorsqu'on est en présence de codes s'exécutant effectivement en parallèle.
</p>
<p>
De plus, Lwt inclut des bibliothèques additionnelles pour faire par exemple
de la programmation événementielle, permettant de créer des threads Lwt représentant
l'attente d'un événement.
</p>
<p>
Enfin, aucun thread en attente ne sera débloqué si l'ordonnanceur (<em>scheduler</em>)
n'est pas lancé, par la fonction <ml>Lwt_main.run</ml>, sur le "thread principal":
</p>
<oc-eval>Lwt_main.run;;</oc-eval>
</subsection>
<subsection id="lwt-syntaxe" title="Syntaxe">
<p>Pour faciliter l'écriture de code utilisant Lwt, la bibliothèque fournit
quelques opérateurs et une extension de syntaxe.
</p>
<p>Plutôt que la fonction <ml>Lwt.bind</ml>, on pourra utiliser deux opérateurs
infixes prenant les mêmes paramètres dans un sens ou dans l'autre:
</p>
<oc-eval><![CDATA[open Lwt;;
(>>=);;
(=<<);;
]]></oc-eval>
<p>Ainsi, les deux codes suivants sont équivalents pour créer un thread Lwt qui,
lorsqu'une ligne aura été saisie sur l'entrée standard, retournera cette ligne
mise en majuscules:
</p>
<oc-eval>Lwt.bind (Lwt_io.read_line Lwt_io.stdin) (fun s -> Lwt.return (String.uppercase s));;
Lwt_io.read_line Lwt_io.stdin >>= fun s -> Lwt.return (String.uppercase s);;
</oc-eval>
<p>La fonction <ml>Lwt.map</ml> permet de ne pas avoir à utiliser <ml>Lwt.return</ml>,
qu'elle utilise pour créer un thread Lwt à partir du résultat d'une fonction:
</p>
<oc-eval>Lwt.map;;</oc-eval>
<p>
Les opérateurs <ml>(>|=)</ml> et <ml>(&lt;|=)</ml> sont équivalents à <ml>Lwt.map</ml>
avec deux façons d'ordonner les paramètres. Ainsi, notre code précédent devient:
</p>
<oc-eval><![CDATA[Lwt.map String.uppercase (Lwt_io.read_line Lwt_io.stdin) ;;
Lwt_io.read_line Lwt_io.stdin >|= String.uppercase;;
String.uppercase =|< Lwt_io.read_line Lwt_io.stdin;;
]]></oc-eval>
<since-version v="4.02.0">
<p>
Lwt fournit également une <doc href="env#preproc">extension ppx</doc> facilitant
encore l'écriture de code. Pour l'activer, on passera l'option <icode>-ppx ppx_lwt</icode>
à <icode>ocaml</icode>, <icode>ocamlc</icode>, ..., ou l'option <icode>-package lwt.ppx</icode>
à <icode>ocamlfind</icode>.
</p>
<p>
La construction
</p>
<ocaml><![CDATA[
let%lwt x = e1
and y = e2 in
code]]></ocaml>
<p>
peut être utilisée à la place de
</p>
<ocaml><![CDATA[
let t = e1
and t2 = e2 in
Lwt.bind t (fun x -> Lwt.bind t2 (fun y -> code)]]></ocaml>
<p>
Ainsi les deux constructions suivantes sont équivalentes:
</p>
<oc-eval>
let p =
  let t = Lwt_io.read_line Lwt_io.stdin in
  Lwt.bind t (fun s -> Lwt.return (String.uppercase s));;
let p =
  let%lwt s = Lwt_io.read_line Lwt_io.stdin in
  Lwt.return (String.uppercase s);;
</oc-eval>
<!--
<oc-eval toplevel="false" show-stdout="false" show-code="false">#use "topfind";;
#camlp4o;;
#require "lwt.syntax";;
</oc-eval>
<p>
La construction
</p>
<ocaml><![CDATA[
lwt x = e1
and y = e2 in
code]]></ocaml>
<p>
peut être utilisée à la place de
</p>
<ocaml><![CDATA[
let t = e1
and t2 = e2 in
Lwt.bind t (fun x -> Lwt.bind t2 (fun y -> code)]]></ocaml>
<p>
Ainsi les deux constructions suivantes sont équivalentes:
</p>
<oc-eval>
let p =
  let t = Lwt_io.read_line Lwt_io.stdin in
  Lwt.bind t (fun s -> Lwt.return (String.uppercase s));;
let p =
  lwt s = Lwt_io.read_line Lwt_io.stdin in
  Lwt.return (String.uppercase s);;
</oc-eval>
<p>
On peut enchaîner des traitements en utilisant l'opérateur <ml>&gt;&gt;</ml>
permettant d'écrire:
</p>
<oc-eval>
Lwt_main.run
  (Lwt_io.(write stdout "hello, " >> write stdout "world!\n" >> flush stdout));;
</oc-eval>
<p>Au lieu de</p>
<oc-eval>
Lwt_main.run
  (Lwt_io.(write stdout "hello, "
           >>= fun _ -> write stdout "world!\n"
           >>= fun _ -> flush stdout));;
</oc-eval>
-->
<p>
La notation <ml>%lwt</ml> peut être utilisée dans d'autres constructions
(<ml>match%lwt ... with</ml>, <ml>try%lwt ... with</ml>, ...);
pour plus de détails, on consultera
<ext-a href="http://ocsigen.org/lwt/2.5.0/api/Ppx_lwt">la documentation</ext-a>.
</p>
</since-version>
<!--
<p>
Pour compiler un programme utilisant l'extension de syntaxe, on utilisera une
commande de la forme
</p>
<sh>$ ocamlfind ocamlc -syntax camlp4o -package lwt.syntax -linkpkg -o foo foo.ml</sh>
<p>La syntaxe est également disponible dans le toplevel, en utilisant les directives
suivantes pour la charger:
</p>
<ocaml>
#use "topfind";;
#camlp4o;;
#require "lwt.syntax";;
</ocaml>
-->
</subsection>

<subsection id="lwt-threads" title="Manipulation des threads">
<p>
Les threads Lwt sont des valeurs OCaml comme les autres, et peuvent
donc être passées à des fonctions. Lwt offre la possibilité d'effectuer
plusieurs opérations sur ses threads. On peut par exemple demander
l'état d'un thread, qui peut être endormi (en attente, <ml>Sleep</ml>),
terminé avec une valeur de retour (<ml>Return of 'a</ml>) ou terminé en
échec (<ml>Fail of exn</ml>).
</p>
<warning id="lwt-run" title="Utilisation de Lwt_main.run">
<p>
Dans les exemples de code qui suivent, <ml>Lwt_main.run</ml> est utilisé
pour "évaluer" le thread en paramètre, c'est-à-dire faire reprendre les
threads en attente d'un événement (comme une entrée/sortie). En pratique,
dans un programme, on n'utilisera cette fonction que sur le thread "principal"
du programme, qui crée les autres.
</p>
</warning>
<p>
Dans l'exemple suivant, nous créons un tuyau (<em>pipe</em>) dont nous obtenons
le canal de lecture <ml>ic</ml> et le canal d'écriture <ml>oc</ml>.
Ensuite, nous créons un thread Lwt <ml>reader</ml> qui lit un caractère dans le
pipe (et donc attend qu'un caractère soit disponible sur le canal
de lecture). Nous affichons ensuite son état avec <ml>Lwt.State</ml>.
Puis nous écrivons un caractère dans le pipe, et redemandons
l'état du thread <ml>reader</ml>. Nous mettons le tout dans une
fonction que nous passons à <ml>Lwt_main.run</ml>, sinon aucun
thread en attente ne serait débloqué:
</p>
<oc-eval>let state_as_string thr =
  match Lwt.state thr with
  Lwt.Return c -> Printf.sprintf "Return with '%c'" c
| Lwt.Fail _ -> "Fail"
| Lwt.Sleep -> "Sleep"
;;
let run () =
  let ic, oc = Lwt_io.pipe () in
  let reader = Lwt_io.read_char ic in
  (* afficher l'état et attendre la fin de l'affichage avec >>= *)
  Lwt_io.write_line Lwt_io.stdout (state_as_string reader)
  >>= fun _ ->
    (* écrire dans le canal et ne pas attendre *)
    ignore(Lwt_io.write_char oc 'a');
    (* bloquer en attendant la terminaison de la lecture dans le canal *)
    reader >>= fun _ ->
      (* afficher le nouvel état du lecteur *)
      Lwt_io.write_line Lwt_io.stdout (state_as_string reader)
;;
Lwt_main.run (run ());;
</oc-eval>
<!--
<p>Notre <ml>reader</ml> est donc en attente. Ecrivons un caractère
dans le pipe et interrogeons à nouveau l'état:
</p>
<oc-eval>
let ic, oc = Lwt_io.pipe () ;;
let reader = Lwt_io.read_char ic ;;
print_endline (state_as_string reader) ;;
Lwt_main.run (Lwt_io.write_char oc 'a');;
print_endline (state_as_string reader) ;;
</oc-eval>
-->
<p>
En pratique, on n'utilisera que rarement la possibilité de connaître l'état
d'un thread Lwt. Par contre, on utilisera des fonctions agissant en fonction
de l'état de threads Lwt, comme la fonction <ml>Lwt.join</ml> qui permet d'attendre
la fin de plusieurs threads Lwt ou <ml>Lwt.choose</ml> qui retourne le même
résultat que le thread Lwt qui termine en premier parmi une liste:
</p>
<oc-eval>let t = Lwt.join
  [ Lwt_io.write_line Lwt_io.stdout "message 1" ;
    Lwt_io.write_line Lwt_io.stdout "message 2" ;
  ] >>= fun _ -> Lwt_io.flush Lwt_io.stdout
  in
  Lwt_main.run t ;;
Lwt_main.run (Lwt.choose  [ Lwt.return 0 ; Lwt.return 42 ; Lwt.return 56 ]) ;;
</oc-eval>
</subsection>

<subsection id="exercices" title="Exercices">

<exercice id="lwt-grep" title="Grep simplifié et multiplexé">
<p>
Nous souhaitons écrire une version simplifiée mais multiplexée de <code>grep</code>.
Le programme prendra en paramètre une chaîne et une liste de fichiers. Si la liste
de fichiers est vide, l'entrée standard sera utilisée.
</p>
<p>A l'aide des <ext-a href="http://ocsigen.org/lwt/api/Lwt_stream">flux Lwt</ext-a>,
on lira en parallèle les lignes des fichiers donnés et, pour chaque ligne, si
elle contient la chaîne recherchée (utilisation du module <moduledoc name="Str"/>,
par exemple), on l'affichera sur la sortie standard.
</p>
<p>Si plusieurs fichiers sont donnés, le nom de chaque fichier suivi de ':' sera
affiché en tête de chaque ligne conservée.
</p>
<p>
Si le code est placé dans un fichier <code>lwt_grep.ml</code>, on pourra compiler
le programme avec la commande suivante:
</p>
<run>ocamlfind ocamlopt -o lwt-grep -package lwt.unix,str -linkpkg lwt_grep.ml</run>
<solution>
<ocaml defer_="1"><codefile file="lwt_grep.ml"/></ocaml>
</solution>
</exercice>

<exercice id="lwt-commands" title="Exécution de commandes dépendantes">
<p>
Lwt permet de paralléliser les attentes non seulement sur les entrées/sorties
mais également sur d'autres processus, comme l'illustre cet exercice.
</p>
<p>
Nous souhaitons exécuter des commandes shell, dont certaines sont
dépendantes d'autres commandes et ne peuvent donc être exécutées
qu'après ces dernières.
</p>
<p>
Plutôt qu'exécuter une à une les commandes après les avoir triées
selon leurs dépendances, nous allons utiliser Lwt pour exécuter
ces commandes le plus possible en parallèle.
</p>
<p>
Ecrire un module <ml>Lwt_commands</ml> offrant l'interface suivante:
</p>
<ocaml defer_="1"><codefile file="lwt_commands.mli"/></ocaml>
<p>
On utilisera notamment des fonctions des modules
<ext-a href="http://ocsigen.org/lwt/api/Lwt_process"><ml>Lwt_process</ml></ext-a>
et <ext-a href="http://ocsigen.org/lwt/api/Lwt_list"><ml>Lwt_list</ml></ext-a>,
ainsi que <ext-a href="http://ocsigen.org/lwt/api/Lwt#VALfail"><ml>Lwt.fail</ml></ext-a>
 pour signaler une erreur.
</p>
<p>
Ce module pourra être compilé par les commandes suivantes:
</p>
<run list="true">
<x>ocamlfind ocamlopt -c -package lwt.unix lwt_commands.mli</x>
<x>ocamlfind ocamlopt -c -package lwt.unix lwt_commands.ml</x>
</run>
<p>
On pourra tester le module avec le code qui suit, ce dernier
créant plusieurs commandes. <ml>clean</ml> permet de s'assurer
que les fichiers <code>file1.txt</code>, <code>file2.txt</code> et <code>file3.txt</code>
sont supprimés. La commande principale lance un <ml>ls -l</ml> sur ces
fichiers et échouera donc s'ils n'existent pas. Elle dépend donc
de trois autres commandes, chacune dormant une seconde avant de
créer un fichier vide. Ces trois commandes dépendent également chacune
de la commande <ml>clean</ml>:
</p>
<ocaml defer_="1"><codefile file="lwt_commands_test.ml"/></ocaml>
<p>
En plaçant le code ci-dessus dans un fichier <code>lwt_commands_test.ml</code>
et en compilant le tout dans un programme <code>lwt-commands</code> avec la
commande suivante:
</p>
<run>ocamlfind ocamlopt -o lwt-commands -package lwt.unix -linkpkg \
  lwt_commands.cmx lwt_commands_test.ml</run>
<p>
nous pouvons vérifier que l'exécution de notre programme parallélise bien
les trois commandes qui créent les trois fichiers, puisque le temps d'exécution
total est d'à peine plus d'une seconde, et non trois si les commandes de création
avaient été exécutées séquentiellement:
</p>
<run>/usr/bin/time -f %E ./lwt-commands</run>
<solution>
<ocaml defer_="1"><codefile file="lwt_commands.ml"/></ocaml>
<p>
Dans la solution proposée, le changement du champ <ml>thread</ml> des
commandes n'est pas protégé, car c'est inutile. En effet, une seule
structure <ml>command</ml> est gérée à la fois par notre fonction
<ml>run</ml>, il n'y a pas de parallélisme, donc pas de concurrence,
car rien n'interrompt notre fonction avant qu'elle ne place le
thread créé (et en attente de son réveil par la suite de la fonction)
dans le champ <ml>thread</ml>.
</p>
</solution>
</exercice>

</subsection>

<subsection id="lwt-conclusion" title="Conclusion">
<p>
Nous n'avons vu qu'un ensemble restreint des possibilités offertes par Lwt. En particulier,
nous n'avons pas évoqué la possibilité d'annuler un thread Lwt, la gestion des exceptions,
les variables locales à un thread Lwt.
</p>
<p>Si l'usage de Lwt présente d'incontestables facilités pour écrire du code fortement
soumis à des attentes longues<note>Lwt est notamment utilisé par
<ext-a href="http://ocsigen.org/">Ocsigen</ext-a>, un serveur web en OCaml qui par nature
passe du temps à attendre et envoyer des messages sur le réseau.</note>, il présente
un inconvénient: les codes qui utilisent une bibliothèque s'appuyant sur Lwt ont tendance
à être "contaminés", les résultats fournis par la bibliothèque en question étant
empaquetés dans les threads Lwt, ce qui pousse à propager la logique de parallélisation
des attentes.
</p>
<p>Symétriquement, dans un code s'appuyant sur Lwt mais souhaitant interagir avec d'autres
bibliothèques n'utilisant pas Lwt, il conviendra de s'assurer qu'aucune opération longue
de ces bibliothèques ne vient bloquer la parallélisation des attentes offertes par Lwt.
Si c'est le cas, on exécutera les parties potentiellement longues ou bloquantes dans
un thread système séparé grâce à la fonction <ml>Lwt_preemptive.detach</ml>
(et on compilera en utilisant en plus le paquet <code>lwt.preemptive</code>).
</p>
<p>Plusieurs bibliothèques OCaml utilisent Lwt ou offrent une partie de leur
interface "en Lwt", notamment pour faciliter l'implémentation de communication
via le réseau, par exemple
<ext-a href="https://github.com/mirage/ocaml-cohttp">cohttp</ext-a> ou
<ext-a href="http://ocurl.forge.ocamlcore.org/">ocurl</ext-a>.
</p>
</subsection>

<subsection id="async" title="Async">
<p>
La bibliothèque <ext-a href="http://janestreet.github.io/">Async</ext-a> est
une alternative à <doc href="#lwt">Lwt</doc>, offrant une interface similaire:
empaquetage des valeurs dans un type <ml>'a Deferred.t</ml>, opérations <ml>bind</ml>
et <ml>return</ml> (bref, une monade).
</p>
<p>
On pourra lire
<ext-a href="https://realworldocaml.org/v1/en/html/concurrent-programming-with-async.html">ce chapitre</ext-a>
(en anglais) de <cite href="rwo"/> pour une présentation et des exemples détaillés.
</p>
<p>
Les effets de contagion du modèle basé sur la monade,
<doc href="#lwt-conclusion">signalés pour Lwt</doc>, sont également présents
avec Async.
</p>
</subsection>

</section>


<section id="threads" title="Processus légers">
<p>Le but de cette introduction n'est pas de présenter ce que
sont les processus légers. On pourra se référer par exemple
à <cite href="sysocaml"/>.
</p>
<p>
Les processus légers sont gérés à l'aide du module
<moduledoc name="Thread"/>. Ils sont disponibles sur les plateformes
Posix 1003.1c et Win32.
</p>
<p>
La compilation de modules utilisant les threads nécessite de passer
l'option <code>-thread</code> aux compilateurs <code>ocamlc</code>
et <code>ocamlopt</code>, ainsi que de lier avec la bibliothèque
<code>threads.cma</code> (pour le code-octet) ou <code>threads.cmxa</code>
(pour le code natif). Comme cette bibliothèque nécessite également
la bibliothèque Unix, on liera le programme final avec aussi
<code>unix.cma</code> ou <code>unix.cmxa</code>.
</p>
<warning id="nativethreads" title="Threads natifs ou émulés">
<p>
Si le système pour lequel est compilé le code utilisant des threads
ne supporte pas les threads, il faut remplacer l'option <code>-thread</code>
par l'option <code>-vmthread</code>. Tous les threads sont alors exécutés
dans le même processus. Cette option n'est cependant disponible que pour
la compilation en code-octet.
</p>
</warning>
<exercice id="thr1" title="Affichages en parallèle">
<p>Un exercice classique d'utilisation des threads est l'affichage
de messages en parallèle.
Ecrire un programme créant 3 threads, qui affiche chacun 10 lignes
de la forme "Je suis le thread X et c'est mon affichage N.".
</p>
<p>Attention à bien attendre la fin des threads, sinon le programme
principal termine, terminant également les threads avant qu'ils aient
fini leur travail.
</p>
<p>
Si le code se trouve dans un fichier <code>thread_print.ml</code>,
on pourra le compiler par la commande suivante:
</p>
<sh>$ ocamlopt -o thread_print -thread unix.cmxa threads.cmxa thread_print.ml</sh>
<solution>
<ocaml id ="thrprint" defer_="1"><codefile file="thread_print.ml"/></ocaml>
</solution>
<p>
En exercice supplémentaire, on pourra utiliser un mutex pour s'assurer
du non entrelacement des sorties.
</p>
</exercice>
<p>
Différents modules sont également disponibles pour la communication
entre threads:
</p>
<ul>
<li><moduledoc name="Mutex"/> pour la gestion des sections critiques (exclusion mutuelle),</li>
<li><moduledoc name="Condition"/> pour attendre ou signaler une condition,</li>
<li><moduledoc name="Event"/> pour une programmation basée sur des événements envoyés
sur des canaux.</li>
</ul>

</section>


<section id="process" title="Processus lourds">
<p>
La majorité des bibliothèques permettant la parallélisation utilise des processus
lourds, exécutés soit en local, soit à distance en se connectant à d'autres machines
pour y créer des processus. Cette organisation des calculs nécessite donc des
copies de données.
</p>
<p>
OCaml, via le module <moduledoc name="Unix"/>, offre l'accès aux appels systèmes
permettant la création de processus (<em>fork</em>), la communication via des
<em>pipes</em> et des <em>sockets</em>, etc. On lira utilement <cite href="sysocaml"/>.
</p>
<p>
Il existe cependant plusieurs bibliothèques offrant des abstractions pour faciliter
ces modèles de calcul parallèle et/ou distribué:
</p>
<ul>
<li><ext-a href="https://github.com/janestreet/async_parallel">Async-parallel</ext-a>,
une extension d'Async pour l'exécution de code en parallèle sur des machines distantes,</li>
<li><ext-a href="http://rdicosmo.github.io/parmap/">Parmap</ext-a> permet l'exécution
de fonctions sur plusieurs <em>cœurs</em>,</li>
<li><ext-a href="http://projects.camlcity.org/projects/ocamlnet.html">OCamlnet</ext-a>,
une bibliothèque offrant beaucoup de fonctions pour développer des applications utilisant
le réseau, contient plusieurs modules pour la programmation parallèle ainsi que
pour le partage de structures de données et le passage de messages,</li>
<li><ext-a href="http://forge.ocamlcore.org/projects/ocamlmpi/">OCamlMPI</ext-a> est
une interface avec la bibliothèque de passage de messages MPI,</li>
<li><ext-a href="http://functory.lri.fr/">Functory</ext-a> est une bibliothèque permettant
d'effectuer des calculs séquentiellement ou en parallèle, soit sur la même machine,
soit sur des machines distantes.</li>
</ul>
<subsection id="functory" title="Functory">
<p>
<ext-a href="http://functory.lri.fr/">Functory</ext-a> présente l'avantage d'avoir
une interface commune pour les différentes façons de distribuer les calculs
à effectuer, ainsi qu'un module pour l'exécution séquentielle, facilitant le
débogage et/ou l'obtention d'un comportement de référence.
</p>
<p>
En guise d'exemple, nous allons écrire un programme qui applique une fonction
à différentes listes d'entiers, la première fois de façon séquentielle,
la seconde en utilisant plusieurs processus locaux.
</p>
<p>
Nous définissons tout d'abord nos listes d'entiers:
</p>
<oc-eval>let input =
  [
    [ 1 ; 2 ; 3 ; 4 ; 5 ; 6 ; 7 ; 8 ; 9 ; 10 ] ;
    [ 2 ; 4 ; 6 ; 8 ; 10 ] ;
    [ -1 ; -7 ; -9 ; -42 ] ;
  ]
;;</oc-eval>
<p>Nous définissons également une fonction sommant une liste d'entiers
en paramètre:
</p>
<oc-eval>let sum = List.fold_left (+) 0;;</oc-eval>
<p>
Enfin, nous utilisons le module de la bibliothèque Functory pour effectuer
les opérations séquentiellement, afin d'appliquer la fonction <ml>sum</ml>
sur chacune de nos listes:
</p>
<oc-eval>Functory.Sequential.map sum input ;;</oc-eval>
<p>
Si nous souhaitons effectuer le même traitement, mais en utilisant plusieurs
cœurs de notre machine, il nous suffit d'indiquer le nombre maximum de cœurs
à utiliser et d'appeler la fonction <ml>map</ml> du module <ml>Functory.Cores</ml>:
</p>
<oc-eval>Functory.Cores.set_number_of_cores 4;;
Functory.Cores.map sum input ;;
</oc-eval>
<p>On peut ainsi, en changeant par exemple un <ml>open</ml>, utiliser
soit le <ml>map</ml> séquentiel, soit le <ml>map</ml> parallèle local.
</p>
<p>
De la même façon, il est possible de lancer les calculs sur des machines
distantes, préalablement déclarées, à l'aide du module <ml>Functory.Network</ml>.
Il y a plusieurs modules, selon que le programme distant sera le même,
ou bien qu'il sera différent mais compilé avec la même version d'OCaml,
ou encore différent et compilé avec une autre version d'OCaml. Dans
l'exemple ci-dessous, nous utilisons le module <ml>Same</ml> car le programme
distant est le même que celui local.
</p>
<ocaml eval="false">Functory.Network.declare_workers ~n: 4 "machine1";;
Functory.Network.declare_workers ~n: 8 "machine2";;
Functory.Network.Same.map sum input ;;
</ocaml>
<p>
Les programmes sur les machines distantes doivent être lancés et
attendre les instructions du maître avec le code suivant:
</p>
<ocaml>Functory.Network.Same.Worker.compute ();;</ocaml>
<p>
Bien sûr, les calculs à répartir sont en général un peu plus gourmands
en temps et/ou en mémoire que notre fonction jouet...
</p>
<p>
La bibliothèque offre d'autres fonctions que <ml>map</ml> pour effectuer
des calculs (différentes variantes de <em>fold</em>), la possibilité
de paramétrer le port par lequel maître et esclaves communiquent, ...
On consultera
<ext-a href="https://www.lri.fr/~filliatr/functory/doc/Functory.html">la documentation</ext-a>
pour en savoir davantage.
</p>
</subsection>

<subsection id="parmap" title="Parmap">
<p>
<ext-a href="http://rdicosmo.github.io/parmap/">Parmap</ext-a>
offre seulement la possibilité d'utiliser plusieurs cœurs de la machine,
mais offre davantage de fonctions, traitant à la fois les listes et
les tableaux.
</p>
<p>Avec notre liste de listes <ml>input</ml> et notre fonction <ml>sum</ml> précédentes,
nous pouvons appliquer <ml>sum</ml> à chacune des listes de la façon suivante,
en utilisant 6 cœurs:
</p>
<oc-eval>Parmap.parmap ~ncores: 6 sum (Parmap.L input);;</oc-eval>
<p>On consultera avantageusement la
<ext-a href="http://rdicosmo.github.io/parmap/doc/Parmap.html">documentation de Parmap</ext-a>
pour découvrir les fonctions offertes pour paralléliser des calculs.
</p>
</subsection>
</section>
<section id="conclusion" title="Conclusion">
<p>
Il existe plusieurs façons de paralléliser des calculs et gérer la concurrence,
chacune pouvant être basée sur des bibliothèques variées.
</p>
<p>
Pour des développements basés sur le modèle à monades évoqué ci-dessus et
utilisant peu d'autres bibliothèques, le choix reste assez
ouvert. Cependant, lorsqu'il s'agit de composer plusieurs bibliothèques existantes,
on s'assurera de leur compatibilité entre elles. En effet, plusieurs bibliothèques
utilisent Lwt, tandis que d'autres se basent sur Async, d'autres n'utilisent ni
l'une ni l'autre et d'autres enfin fournissent des implémentations pour les deux.
</p>
<p>
Le choix du modèle de parallélisme sort du cadre de cette introduction. On signalera
simplement qu'il est orienté par certaines contraintes comme la taille des données
manipulées (en cas de copie, transfert, ...), la disponibilité ou non de noeuds
de calculs, distribués ou non.
</p>
<p>
La programmation purement fonctionnelle facilite le développement de codes de
calcul parallèle. OCaml est donc naturellement un bon choix pour ce style
de programmation.
</p>
</section>
</contents>
</module>